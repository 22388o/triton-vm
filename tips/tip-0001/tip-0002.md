# TIP 0002: Contiguity Argument for Memory Consistency

| TIP            | 0002                                       |
|:---------------|:-------------------------------------------|
| authors:       | Alan Szepieniec                                  |
| title:         | Multi-Table Subset Argument for Memory Consistency |
| status:        | draft                                      |
| created:       | 2022-08-25                                 |
| issue tracker: |                                                                                          |

**Abstract.** In the current specification, the memory-like tables `RamTable`, `JumpStackTable`, and `OpStackTable` do not satisfy memory-consistency. Specifically, they are vulnerable to [Yuncong's attack](https://github.com/TritonVM/triton-vm/issues/12), which exploits the unverified and thus possibly-incorrect sorting in these tables. This TIP addresses one part of the issue by introducing a new table argument, the *multi-table subset argument*. It establishes that certain values in different tables have a matching representative in a given lookup table. Applied to the present context, this technique establishes that every clock jump is positive. This note is a companion to TIP-0001, which introduces an new argument to establish the contiguity of regions of constant memory pointer. Together, TIP-0001 and TIP-0002 fix the memory consistency issue.

## Introduction

How to establish that a clock jump is directed forward (as opposed to direct backward, which would indicate malicious behavior)? One strategy is to show that the *difference*, *i.e.*, the next clock cycle minus the current clock cycle, is itself a clock cycle. Recall that the Processor Table's clock cycles run from 0 to $T-1$. Therefore, valid differences belong to $\lbrace 2, ..., T-1 \rbrace$ and invalid ones to $\lbrace p - T + 1, ..., p - 2 \rbrace$.

Standard subset arguments can show that the clock jump differences are elements of the Processor Table's clock cycle column. However, it is cumbersome to repeat this argument for three separate tables.

I present here a Polynomial IOP / RAP hybrid argument for showing that all clock jump differences in all three memory-like tables live also in the Processor Table's `clk` column. It introduces one extension column in each memory-like table; one extension column in Processor Table; and three committed polynomials that do not correspond to any columns.

## Intuition

Let $f(X)$ denote the polynomial

$$ f(X) = \left( \prod_{\delta_r} (X - \delta_r) \right) \cdot \left( \prod_{\delta_o} (X - \delta_o) \right) \cdot \left( \prod_{\delta_j} (X - \delta_j) \right) $$

where the $\delta_r$, $\delta_o$, and $\delta_j$ denote the clock jump differences in the Ram Table, OpStack Table, and Jump Stack Table, respectively.

This polynomial can be (and is) evaluated in a scalar $\alpha$ supplied by the verifier through three running products. (All three running products use the same challenge $\alpha$.) However, it is additionally committed to. The point $\alpha$ is used to verify that the committed polynomial $[f(X)]$ does indeed correspond to the product of running product columns.

Expand the Processor Table with a new column `cji` ("clock jump indicator") which takes the value 1 if the `clk` value is also the value of some clock jump, and 0 otherwise. The extension column computes the value of the polynomial 

$$h(X) = \prod_\delta (X - \delta)$$

in some scalar $\beta$ supplied by the verifier, where $\delta$ ranges over the values of `clk` in indicated rows.

Note that the roots of $f(X)$ correspond to roots of $h(X)$. However, the roots occur with various multiplicities in $f(X)$ and with multiplicity 1 in $h(X)$. To harmonize the multiplicities, we need the formal derivative $f'(X)$ of $f(X)$ to cancel all the square factors. Specifically, let $g(X) = \gcd(f(X), f'(X))$ then $h(X) g(X) = f(X)$ and to establish the correct gcd relation we need Bézout coefficients $a(X)$ and $b(X)$ for the Bézout relation

$$ a(X) f(X) + b(X) f'(X) = g(X) . $$

## Detailed Description

### Memory-like Tables

Here are the constraints for the RAM Table. The constraints for other two tables are analogous and are therefore omitted. The constraints are relative to the indeterminate $X$ which anticipates the verifier's challenge $\alpha$ via the implicit substitution $X \mapsto \alpha$.

Use $\mathsf{mp}$ to abstractly refer to the memory pointer. The extension column starts with a random initial $\mathsf{rp}_I \in \mathbb{F}$ and no boundary constraints. The transition constraint enforces the accumulation of a factor $(X - \mathsf{clk}^\star + \mathsf{clk})$ whenever there is a clock jump and the memory pointer is the same. If there is no clock jump or the memory pointer is unchanged, the same running product is carried to the next row. The transition constraint is

$$ (\mathsf{mp}^\star - \mathsf{mp}) \cdot (\mathsf{clk}^\star - \mathsf{clk} - 1) \cdot (\mathsf{rp}^\star - \mathsf{rp} \cdot (X - \mathsf{clk}^\star + \mathsf{clk})) + (\mathsf{mp}^\star - \mathsf{mp}) \cdot (\mathsf{clk}^\star - \mathsf{clk}) \cdot (\mathsf{rp}^\star - \mathsf{rp}) + ( 1 - (\mathsf{mp}^\star - \mathsf{mp}) \cdot \mathsf{di} ) \cdot \left( \mathsf{rp}^\star - \mathsf{rp} \right) \enspace .$$

Note that $\mathsf{di}$ is the difference inverse of the Ram Table but for the other two tables this factor can be dropped.

The running product has a terminal $\mathsf{rp}_T$ but a trivial terminal constraint: $\mathsf{rp} - \mathsf{rp}_T$.

The prover computes $\mathsf{rp}_T(X)$ symbolically for every memory-like table. The polynomial $f(X)$ is the product of all such symbolic terminals.

### Processor Table

The Processor Table also has a running product extension column `rp`. In the first row it is unconstrained and set to a random initial $\mathsf{rp}_I$. In every row it is either updated with a factor $(X - \mathsf{clk})$ or not – the prover knows what to do. The verifier only needs to verify the transition constraint $(\mathsf{rp}^\star - \mathsf{rp}) \cdot (\mathsf{rp}^\star - \mathsf{rp} \cdot (X - \mathsf{clk}))$. The terminal constraint is likewise $(\mathsf{rp}_T - \mathsf{rp}) \cdot (\mathsf{rp}_T - \mathsf{rp} \cdot (X - \mathsf{clk}))$

The formal indeterminate $X$ here anticipates the verifier's second challenge $\beta$. The prover computes $\mathsf{rp}_T$ symbolically before $\beta$ is supplied – in fact, this symbolic terminal is the polynomial $h(X)$.

### Square-Freeness Argument

All memory-like tables' clock jump differences are members of the Processor Table's `clk` column if $h(X)$ is the maximal [square-free](https://en.wikipedia.org/wiki/Square-free_polynomial) divisor of $f(X)$. This relation is implied by three points:
 - $f'(X)$ is the formal derivative of $f(X)$
 - $g(X)$ is the greatest common divisor of $f(X)$ and $f'(X)$
 - $h(X) = f(X) / g(X)$.

To see this, let $f(X) = \prod_i f_i(X)^{m_i}$. Then $f'(X) = \sum_i m_i f_i(X)^{m_i - 1} f_i'(X) \prod_{j \neq i} f_j(X)$. And $g(X) = \prod_i f_i(X)^{m_i-1}$ because every factor in the product appears in all terms of $f'(X)$, but there will be one term that limits the multiplicity to $m_i-1$. And from this it follows that $h(X) = f(X) / g(X)$.

Note that is is possible to eliminate $g(X) = f(X) / h(X)$ from the above bullet points. Therefore, two relations remain to be shown: the formal derivative, and the gcd.

### Greatest Common Divisor

Let $a(X)$ and $b(X)$ be randomized Bézout coefficients such that 

$$ a(X) f(X) + b(X) f'(X) = g(X) \enspace .$$

Specifically, the prover computes coefficients $a^\star(X)$ and $b^\star(X)$ using the [extended Euclidean algorithm](https://en.wikipedia.org/wiki/Extended_Euclidean_algorithm). Then he samples a random factor $k(X)$ of degree at most 2 and sets $a(X) = a^\star(X) + k(X) f'(X)$ and $b(X) = b^\star(X) - k(X) f(X)$.

The verifier probes this identity of polynomials in a randomly chosen point $z_1 \xleftarrow{\$} \mathbb{F}$.

### Formal Derivative

The formal derivative of a polynomial $f(X) = \sum_{i=0}^d c_i X^i$ is $f'(X) = \sum_{i=1}^d c_i i X^{i-1}$. The correct relation between two polynomial oracles $[f(X)]$ and $[f'(X)]$ can be verified by probing the relation $X \cdot f'(X) = (N_d \circ f)(X)$, where $N_d(X) = \sum_{i=1}^d iX^i$ is the natural arithmetic polynomial up to some degree bound $d \geq \deg(f(X))$, and where $\circ$ denotes the Hadamard (coefficient-wise) product.

Note that the natural arithmetic polynomial can be evaluated efficiently via the following recursive relation.

$$ N_d(X) = \sum_{i=1}^d i X^i = \sum_{i=0}^{\frac{d+1}{2}-1} i X^i + \sum_{i=0}^{\frac{d+1}{2}-1} (\frac{d+1}{2} + i) X^{\frac{d+1}{2}+i} $$

$$ = \sum_{i=0}^{\frac{d+1}{2} - 1} iX^i + X^{\frac{d+1}{2}} \cdot \left( \frac{d+1}{2} \sum_{i=0}^{\frac{d+1}{2}-1} X^i + \sum_{i=0}^{\frac{d+1}{2}-1}iX^i \right) $$

$$ = \left(1 + X^{\frac{d+1}{2}} \right) \sum_{i=0}^{\frac{d+1}{2}-1} iX^i + \frac{d+1}{2} \cdot X^{\frac{d+1}{2}} \cdot \frac{X^{\frac{d+1}{2}}-1}{X-1}$$

$$ = \left(1 + X^{\frac{d+1}{2}} \right) N_{\frac{d+1}{2}-1}(X) + \frac{d+1}{2} \cdot \frac{X^{d+1}-X^{\frac{d+1}{2}}}{X-1}$$

Therefore, no further polynomial oracles are required to verify the formal derivative relation beyond those that are required to verify the Hadamard relation. For verifying the Hadamard relation, the §3.5 of the [Claymore paper](https://eprint.iacr.org/2020/1022.pdf) provides a solution, which is summarized below in unrolled form.

 - The verifier samples $\alpha \xleftarrow{\$} \mathbb{F} \backslash \{0\}$ and sends $\eta$ to the prover.
 - The prover computes the coefficient vector $\mathbf{c}$ of $N_d(\alpha \cdot X) \cdot f(X^{-1}) \cdot X^d$ and the polynomial $\bar{h}(X) = \sum_{i=0}^{2d} h_i X^i$, where the $i$ th coefficient is $h_i = \frac{c_i}{\gamma^d - \gamma^i}$ and $h_d \xleftarrow{\$} \mathbb{F}$. The prover sends $\bar{h}(X)$ to the verifier along with the implicit claim that its degree is bounded by $2d$. Here $\gamma \in \mathbb{F}$ is some system-wide parameter with a sufficiently large multiplicative order.
 - The verifier probes the polynomial identity $\bar{h}(X) \cdot \gamma^d - \bar{h}(\gamma X) + \alpha \cdot f'(\alpha) \cdot X^d = N_d(\alpha \cdot X) \cdot f(X^{-1}) \cdot X^d$ in a random point $z \xleftarrow{\$} \mathbb{F} \backslash \{0\}$.

### Putting Everything Together

 1. The prover computes $f(X)$, $h(X)$, $f'(X), a(X), b(X)$ and all base columns.
 2. The prover commits to $f(X)$, $a(X)$, $b(X)$ and to all base columns.
 3. The verifier supplies uniformly random challenges $\alpha, \beta, z$.
 4. The prover computes the extension columns, and $\bar{h}(X)$, and commits to them. He also reveals the terminals.
 5. Let $\alpha$ be the challenge for the Processor Table's running product such that $h(\alpha) = \mathsf{rp}_T$. The prover reveals $a(\alpha), b(\alpha), f(\alpha)$. Note that $f'(\alpha) = \frac{a(\alpha)f(\alpha) - f(\alpha)/h(\alpha)}{b(\alpha)}$.
 7. The prover reveals $f(z^{-1})$, $\bar{h}(z)$ and $\bar{h}(\gamma z)$.
 8. The verifier probes the polynomial identity $\bar{h}(X) \cdot \gamma^d - \bar{h}(\gamma X) + \alpha \cdot f'(\alpha) \cdot X^d = N_d(\alpha \cdot X) \cdot f(X^{-1}) \cdot X^d$ in $X=z$ with the revealed values.
 9. Let $\beta$ be the challenge for computing the running products of the memory-like tables, resulting in three terminals which, multiplied together, give $f(\beta)$. Let $i_f(X)$ be the lowest-degree interpolant through $(\alpha, f(\alpha)), (\beta, f(\beta)), (z, f(z))$, and $i_{\bar{h}}(X)$ the lowest-degree interpolant through $(z, \bar{h}(z)), (\gamma z, \bar{h}(\gamma z))$. Add to the nonlinear combination:
   - the polynomials $f(X), a(X), b(X), \bar{h}(X)$ of degrees at most $T+3$, $T+2$, $T+3$, and $2T+6$, respectively.
   - the quotient $\frac{f(X) - i_f(X)}{(X-\alpha)(X-\beta)(X-z)}$ of degree at most $T$
   - the quotient $\frac{a(X) - a(\alpha)}{X - \alpha}$ of degree at most $T+1$
   - the quotient $\frac{b(X) - b(\alpha)}{X - \alpha}$ of degree at most $T+2$.
   - the quotient $\frac{\bar{h}(X) - i_{\bar{h}}(X)}{(X - z)(X-\gamma z)}$ of degree at most $2T+4$.

## Security

[todo]
